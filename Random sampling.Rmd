For random selection
```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(MASS)
library(stats)
library(purrr)
library(truncnorm)
library(posterior)
library(deSolve)
library(bayestestR)
library(coda)

noise_BG= 0.221
noise_SC=0.5

MU_M = c(0.1,50)
K_D = c(0.0001,1)
Yield_C = c(0.01,10)
param_matrix=matrix(c(MU_M[1],K_D[1],Yield_C[1],MU_M[2],K_D[2],Yield_C[2]),nrow=1,byrow=FALSE)
```
Define function
```{r}
original_function = function(T_2, MU_M, K_D, Yield_C) {
  param=c( MU_M=MU_M, K_D=K_D, Yield_C=Yield_C)  
  states=c(BG=0.014, SC=4.051)
  bacmodel=function(t,states,param){
    with(as.list(c(states,param)),{
      dBG = ((MU_M*SC)/(12+SC))*BG-K_D*BG;
      dSC = -(1/Yield_C)*((MU_M*SC)/(12+SC))*BG;
      list(c(dBG,dSC))
    })
  }
  times=c(0,T_2)
  simu=ode(y=states,times=times,func = bacmodel,parms = param)
  return(simu[2,2:3])  
}

similar_function = function(info,num_points=60) {
  n_samples = nrow(info)
  n_T2 = num_points
  unique_T2 = seq(1,num_points,1)
  y1_values = matrix(nrow = n_samples, ncol = n_T2)
  y2_values = matrix(nrow = n_samples, ncol = n_T2)
  for (i in 1:n_samples) {
    MU_M = info[i, "MU_M"]
    K_D = info[i, "K_D"]
    Yield_C = info[i, "Yield_C"]
    bacmodel = function(t, states, param) {
      with(as.list(c(states, param)), {
        dBG = ((MU_M * SC) / (12 + SC)) * BG - K_D * BG
        dSC = -(1 / Yield_C) * ((MU_M * SC) / (12 + SC)) * BG
        list(c(dBG, dSC))
      })
    }
    states = c(BG = 0.014, SC = 4.051)
    param = c(MU_M = MU_M, K_D = K_D, Yield_C = Yield_C)
    times = c(0, unique_T2)
    simu = ode(y = states, times = times, func = bacmodel, parms = param)
    simu_df = as.data.frame(simu)
    for (j in 1:n_T2) {
      T2 = unique_T2[j]
      idx = which(simu_df$time == T2)
      if (length(idx) == 1) {
        y1_values[i, j] = simu_df$BG[idx]
        y2_values[i, j] = simu_df$SC[idx]
      } else {
        y1_values[i, j] = NA
        y2_values[i, j] = NA
      }
    }
  }
  df_y1 = as.data.frame(y1_values)
  df_y2 = as.data.frame(y2_values)

  return(list(y1 = df_y1, y2 = df_y2))
}

update_repeat_dict = function(contain_index_pairs, existing_dict) {
  if (is.null(existing_dict)) {
    existing_dict = list()
  }
  for (pair in contain_index_pairs) {
    key = paste(pair, collapse = "_")
    if (!is.null(existing_dict[[key]])) {
      existing_dict[[key]] = existing_dict[[key]] + 1
    } else {
      existing_dict[[key]] = 1
    }
  }
  return(existing_dict)
}

generate_obs = function(idx_pair, seed, repeated_dict, noise_1=noise_BG, noise_2=noise_SC) {
  key = paste(idx_pair, sep = "_")
  repeated_times = repeated_dict[[key]]
  if (is.null(repeated_times)) {
    stop("Counting error, does not exist in the dictionary")
  }
  seed = 30*seed +sum(unlist(repeated_dict))
  set.seed(seed)
  obss=original_function(idx_pair, 3.1, 0.1 ,0.25)#here idx_pair consists only of the idx for T_2
  obs1 =obss[1]+ rtruncnorm(1,a=-obss[1],b=Inf, mean = 0, sd = noise_1)
  obs2 =obss[2]+ rtruncnorm(1, a=-obss[2], b=Inf, mean = 0, sd = noise_2)
  return(list(obs1, obs2))
}
```

Search for MLE  
```{r}
negative_log_likelihood_profile = function(parameters, obs1, obs2, T_2, noise_1, noise_2, fixed_param = NULL, param_index = NULL) {
    if (!is.null(fixed_param) && !is.null(param_index)) {
        full_params = numeric(3)
        full_params[param_index] = fixed_param  
        full_params[-param_index] = parameters  # Optimize the other parameters while fix one
    } else {
        full_params = parameters 
    }
    MU_M = full_params[1]
    K_D = full_params[2]
    Yield_C = full_params[3]
    n = length(T_2)
    pred_BG = numeric(n)
    pred_SC = numeric(n)
    for (idx in seq_along(T_2)) {
      simu = original_function(T_2[idx], MU_M, K_D, Yield_C)
      if (any(is.na(simu))) {
        return(Inf)
      }
      pred_BG[idx] = simu[1]
      pred_SC[idx] = simu[2]
    }
    likelihood_obs1 = dtruncnorm(obs1, a = 0, b = Inf, mean = pred_BG, sd = noise_1)
    likelihood_obs2 = dtruncnorm(obs2, a = 0, b = Inf, mean = pred_SC, sd = noise_2)
    likelihood_obs1[likelihood_obs1 <= 0 | is.na(likelihood_obs1)] = 1e-10
    likelihood_obs2[likelihood_obs2 <= 0 | is.na(likelihood_obs2)] = 1e-10
    total_neg_loglik = -sum(log(likelihood_obs1)) - sum(log(likelihood_obs2))
    return(total_neg_loglik)
}


```

Discretisation
```{r}
single_pid=function(LBs,UBs){
  check_vector = ifelse(is.na(LBs) | is.na(UBs), 0, 1)
  return(check_vector)
}

common_optim_settings = list(
  method = "L-BFGS-B",
  noise_1 = noise_BG,
  noise_2 = noise_SC,
  control = list(maxit = 1000)  # Maximum iterations
)


compute_profile_likelihood = function(fix_param_value, init_params,fix_idx) {
  settings = list(
    par = init_params, 
    fn = negative_log_likelihood_profile,
    obs1 = y_1,
    obs2 = y_2,
    T_2 = T_2,
    fixed_param = fix_param_value, 
    param_index = fix_idx,  # Index for 1MU_M, 2K_D, 3YC
    lower = params_matrix[1, 1:3][-fix_idx],  
    upper = params_matrix[1, 4:6][-fix_idx]   
  )
  pl = do.call(optim, modifyList(common_optim_settings, settings)) 
  #merge before call, so I dont need to type same thing all time
  neglog_lik = pl$value # negloglik
  optimized_two = pl$par
  optimized_params = numeric(length(init_params) + 1)
  optimized_params[-fix_idx] = optimized_two  
  optimized_params[fix_idx] = fix_param_value    
  
  return(list(neglog_lik = neglog_lik, optimized_params = optimized_params))
}



bound_search_ci = function(f, MLE, tol, initial_param, LB, UB, threshold, fix_idx, prev_bound=NULL,max_iter = 50) {
  # Check parameter boundaries
  pl_LB = f(LB, initial_param, fix_idx)$neglog_lik
  pl_UB = f(UB, initial_param, fix_idx)$neglog_lik

  min_pt = numeric(length(initial_param) + 1)
  min_pt[-fix_idx] = initial_param
  min_pt[fix_idx] = MLE
  min_pl = threshold - qchisq(0.95, 1) / 2
 
  if ((pl_LB < threshold || pl_UB < threshold)) {
    cat("Not identifiable for parameter", fix_idx, "\n")
    if (fix_idx == 2) {
      cat("pl opt:", min_pl, "bounds values", pl_LB, "and ", pl_UB, "thres", threshold, "\n")
    }
    return(list(closest_lower = NA, closest_upper = NA, iterations_lower = NA, iterations_upper = NA, best_pl = min_pl, update_MLE = min_pt))
  }
  search_points = data.frame(point = numeric(0), value = numeric(0), region = character(0))
  # Bisection search for the lower interval
  lower = LB
  upper = MLE
  iter = 0
  
  while (abs(upper - lower) > tol && iter < max_iter) {
    mid = (lower + upper) / 2
    pl_mid = f(mid, initial_param, fix_idx)$neglog_lik
    search_points = rbind(search_points, data.frame(point = mid, value = pl_mid, region = "lower"))

    if (abs(pl_mid - threshold) < min_pl) {
      min_pl = abs(pl_mid - threshold)
      min_pt[fix_idx] = mid
    }
    if (pl_mid < threshold) {
      upper = mid
    } else {
      lower = mid
    }
    iter = iter + 1
  }
  
  if (iter == 0) {
      cat(sprintf("Loop did not execute: Using initial mid. MLE=%s ", MLE ))
      closest_lower=(LB+MLE)/2
    } else {
      closest_lower = mid
    }
  iter_lower=iter
  # Bisection search for the upper interval
  lower = MLE
  upper = UB
  iter = 0
  while (abs(upper - lower) > tol && iter < max_iter) {
    mid = (lower + upper) / 2
    pl_mid = f(mid, initial_param, fix_idx)$neglog_lik
    search_points = rbind(search_points, data.frame(point = mid, value = pl_mid, region = "upper"))

    if (abs(pl_mid - threshold) < min_pl) {
      min_pl = abs(pl_mid - threshold)
      min_pt[fix_idx] = mid
    }
    if (pl_mid < threshold) {
      lower = mid
    } else {
      upper = mid
    }
    iter = iter + 1
  }
  if (iter == 0) {
      cat(sprintf("Loop did not execute: Using initial mid. MLE=%s", MLE))
      closest_upper=(UB+MLE)/2
  } else {
      closest_upper = mid
  }
  return(list(closest_lower = closest_lower, closest_upper = closest_upper, iterations_lower = iter_lower, iterations_upper = iter, update_MLE = min_pt, best_pl = min_pl))
}

```

Joint work: update_functions (identifiability) 
```{r}
update_functions_id = function(y_1, y_2, N, T_2, num_points,prev_MLE=c(3,0.5,1),prev_opt = NULL,
                               previous_model=NULL,prev_bound=NULL,params_matrix=param_matrix){ 
  params_matrix<<-params_matrix
  y_1 <<- y_1
  y_2 <<- y_2
  T_2 <<- T_2
  lowerbound = params_matrix[1,1:3]
  upperbound = params_matrix[1,4:6]
  colnames(params_matrix) = c("MU_ML", "K_DL", "Yield_CL", "MU_MU", "K_DU", "Yield_CU")
  func_df = list()
  planalysis = list() 
  i = 1
  optim_results_mle = optim(
    par = prev_MLE,  # Initial guesses all
    fn = negative_log_likelihood_profile,
    obs1 = y_1,
    obs2 = y_2,
    T_2 = T_2,
    noise_1 = noise_BG,
    noise_2 = noise_SC,
    method = "L-BFGS-B",
    lower = params_matrix[1, 1:3],  
    upper = params_matrix[1, 4:6],  
    control = list(maxit = 5000,factr = 1e5)
  )
  mle_params = optim_results_mle$par
  if (!is.null(prev_opt)){
  prev_pl = negative_log_likelihood_profile(
  parameters = prev_opt,
  obs1 = y_1,
  obs2 = y_2,
  T_2 = T_2,
  noise_1 = noise_BG,
  noise_2 = noise_SC
  )
  }else
  prev_pl = 1000
  current_pl =negative_log_likelihood_profile(
  parameters = mle_params,
  obs1 = y_1,
  obs2 = y_2,
  T_2 = T_2,
  noise_1 = noise_BG,
  noise_2 = noise_SC
)
  mle_params = if (current_pl<prev_pl) mle_params else prev_MLE
  MLE_neglog = if (current_pl<prev_pl) current_pl else prev_pl

  optimalestimates = as.numeric(c(mle_params[1], mle_params[2], mle_params[3]))
  OE1 = optimalestimates[1]
  OE2 = optimalestimates[2]
  OE3 = optimalestimates[3]
  #new version of ID check
  min_stepsize=c(0.1,1e-4,1e-2)
  thresholds =compute_profile_likelihood(optimalestimates[1], c(optimalestimates[-1]), 1)$neglog_lik+qchisq(0.95, 1) / 2
  param_indices = 1:3
  bounds = lapply(param_indices, function(i) {
    bound_search_ci(
      f = compute_profile_likelihood,
      MLE = get(paste0("OE", i)),  
      tol = min_stepsize[i],          
      initial_param = c(OE1, OE2, OE3)[-i],
      LB = lowerbound[[i]],                
      UB = upperbound[[i]],                
      threshold = thresholds,             
      prev_bound=as.numeric(prev_bound[i,1:2]),
      fix_idx = i,                          
      max_iter = 50             #max iter for bound search, can be 30-100        
    )
  }) 
  bounds_df = bounds_df =do.call(rbind, lapply(bounds, function(x) {
  as.data.frame(x[1:4])
  }))
  best_pl_values = sapply(bounds, function(x) x$best_pl)
  min_best_pl_index = which.min(best_pl_values)
  update_MLE = bounds[[min_best_pl_index]]$update_MLE
  
  id_check=single_pid(bounds_df$closest_lower,bounds_df$closest_upper)
  cat("Id check for iter", length(T_2) - 1, "is", paste(id_check, collapse = " "), "\n")
  next_location = sample(seq(1, num_points, 1) , 1)
  cat("selected location:", next_location, "\n")
  return(list(next_location, optimalestimates,id_check,current_model=NULL,bounds_df))
}
```

Joint work: each trial
```{r}
iteration_func=function(seed,candidate_T2,iterations,num_points,noise_1=noise_BG, noise_2=noise_SC){
  cat("trial: ", seed)
  set.seed(seed)
  
  estimate_df = list()
  MAP_estimate_df = list()
  estimate_df = list()
  pid_df=list()#practical identifiabiity decisions
  bounds_df=list()
  
  num = num_points
  index_list = 1:num
  N = 1  # start with more points maybe
  selected_T2 = c(24,sample(candidate_T2, N-1, replace = TRUE))
  cat("Initial T2:",selected_T2,"\n")
  contain_pairs = list()
  for (i in 1:N) {
    contain_pairs[[i]] = c(selected_T2[i])
  }
  repeat_count = update_repeat_dict(contain_pairs, list())
  obs1=numeric(0)
  obs2=numeric(0)
  for (idx in 1:length(contain_pairs)){
    obs_generated = generate_obs(contain_pairs[[idx]],seed,repeat_count)
    obs1 =c(obs1, as.numeric(obs_generated[1]))
    obs2 = c(obs2, as.numeric(obs_generated[2]))
  }
  y_1 = obs1
  y_2 = obs2
  cat("Initial contain y:",str(y_1))
  cat("Initial contain idx:",str(contain_pairs))
  result_iter=update_functions_id(y_1[order(unlist(contain_pairs))],y_2[order(unlist(contain_pairs))],N,T_2=sort(unlist(contain_pairs),decreasing=FALSE),num_points)   
  #with initial random observations
  next_location = result_iter[[1]]
  current_mle=result_iter[[2]]
  id_check = result_iter [[3]]
  current_model=result_iter[[4]]
  current_bound=result_iter[[5]]
  
  estimate_df[[i]] = current_mle 
  observations_df = data.frame(iteration = integer(), y1 = list(), y2 = list()) 
  i=0
  while (i < iterations) {
    i = i + 1
    N = N + 1
    contain_pairs = c(contain_pairs, list(next_location))
    repeat_count = update_repeat_dict(next_location, repeat_count)
    obs1 = c(obs1, generate_obs(next_location, seed, repeat_count)[[1]])
    obs2 = c(obs2, generate_obs(next_location, seed, repeat_count)[[2]])
    cat("\n","obs1 is",obs1)
    cat("obs2 is",obs2)
    cat("contain_pairs:",T_2=unlist(contain_pairs),"\n")
    y_1 = obs1
    y_2 = obs2
    cat("enter iteration",i,"\n")
    current_estimate = c(3,0.5,1)
    current_estimate[id_check == 1] = current_mle[id_check == 1]
    result_iter=update_functions_id(y_1[order(unlist(contain_pairs))],y_2[order(unlist(contain_pairs))],N,T_2=sort(unlist(contain_pairs),decreasing=FALSE),num_points,prev_MLE=current_estimate,prev_opt = current_mle,previous_model = current_model,prev_bound=current_bound) 
    set.seed(seed)
    for (j in 1:i){
      sample(candidate_T2, 1, replace = TRUE) 
    }
    next_location = sample(candidate_T2, 1, replace = TRUE)
    current_mle=result_iter[[2]]
    id_check=result_iter[[3]]
    current_model=result_iter[[4]]
    
    estimate_df[[i]] = current_mle
    pid_df[[i]]=id_check
    observations_df = rbind(observations_df, data.frame(iteration = i,y1 = I(list(y_1)),y2 = I(list(y_2))))
    bounds_df[[i]]=result_iter[[5]]
  }
  cat("Final contain:", unlist(contain_pairs), "\n")
  return(list(estimate_df,pid_df,observations_df,contain_pairs,bounds_df))
}

```

Trial function:
```{r}

trials = function(num_trials, iterations, num_points,noise_1=noise_BG, noise_2=noise_SC){
  trialseq = seq(1, num_trials)
  T_2= seq(1, num_points, 1) 
  estimated_params=list()
  observations=list()
  pl_check=list()
  bounds=list()
  obs_locations_df = data.frame(matrix(ncol = length(iterations+1), nrow = 0))
  for (i in 1:length(trialseq)) {
    cat("Start trial",i,"\n")
    #In our experiment, we used seed 1 to 8 and 101 to 108.
    results=iteration_func(trialseq[i]+100,T_2,iterations,num_points)
    estimated_params[[i]]=results[1]
    pl_check[[i]]=results[2]
    observations[[i]]= results[3] #results 4 is dataframe, so a list of dataframe structure
    row_df = as.data.frame(t(unlist(results[[4]])))
    obs_locations_df=rbind(obs_locations_df, row_df)
    bounds[[i]]=results[5]
  }
  save(estimated_params, observations, obs_locations_df,pl_check,bounds, file = "random.RData")
  return(list(estimated_params,observations,obs_locations_df,pl_check,bounds)) 
}

milly=trials(8,30,60) 
```

